{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from copy import deepcopy\n",
    "\n",
    "from src.data import *\n",
    "from src.model import *\n",
    "from src.recourse import *\n",
    "from src.utils import *\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_result(d, alg_name, seed, alpha, lamb, i, x_0, theta_0, beta, x_r, theta_r, p, theta_p, J_r, J_c, robustness, consistency):\n",
    "    d['alg'].append(alg_name)\n",
    "    d['seed'].append(seed)\n",
    "    d['alpha'].append(alpha)\n",
    "    d['lambda'].append(lamb)\n",
    "    d['i'].append(i)\n",
    "    d['x_0'].append(x_0.round(4))\n",
    "    d['theta_0'].append(theta_0.round(4))\n",
    "    d['beta'].append(beta)\n",
    "    d['x_r'].append(x_r.round(4))\n",
    "    d['theta_r'].append(theta_r.round(4))\n",
    "    d['p'].append(p)\n",
    "    d['theta_p'].append(theta_p.round(4))\n",
    "    d['J_r'].append(J_r)\n",
    "    d['J_c'].append(J_c)\n",
    "    d['robustness'].append(robustness)\n",
    "    d['consistency'].append(consistency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recourse_runner(seed: int, X_train: np.ndarray, X: np.ndarray, lar_recourse: LARRecourse, roar_recourse: ROAR, base_model: NN, params: dict, dataset: Dataset):\n",
    "    alpha = params['alpha']\n",
    "    lamb = params['lamb']\n",
    "    params['algs'] = [alg.lower() for alg in params['algs']]\n",
    "    betas = np.arange(0., 1.01, 0.01).round(2)\n",
    "    \n",
    "    results_opt = {'alg': [], 'seed': [], 'alpha': [], 'lambda': [], 'i': [], 'x_0': [], 'theta_0': [], 'beta': [], 'x_r': [], 'theta_r': [], 'p': [], 'theta_p': [], 'J_r': [], 'J_c': [], 'robustness': [], 'consistency': []}\n",
    "    results_roar = deepcopy(results_opt)\n",
    "    \n",
    "    n = len(X)\n",
    "    for i in tqdm.trange(n, desc=f'Evaluating recourse | alpha={alpha}; lambda={lamb}', colour='#0091ff'):\n",
    "        x_0 = X[i]\n",
    "        J = RecourseCost(x_0, lamb)\n",
    "        \n",
    "        # LIME approximation of original NN\n",
    "        np.random.seed(i)\n",
    "        weights_0, bias_0 = lime_explanation(base_model.predict, X_train, x_0)\n",
    "        weights_0, bias_0 = np.round(weights_0, 4), np.round(bias_0, 4)\n",
    "        theta_0 = np.hstack((weights_0, bias_0))\n",
    "        \n",
    "        # Initalize recourse methods with theta_0\n",
    "        lar_recourse.weights = weights_0\n",
    "        lar_recourse.bias = bias_0\n",
    "        roar_recourse.set_weights(weights_0)\n",
    "        roar_recourse.set_bias(bias_0)\n",
    "        \n",
    "        \n",
    "        # Robust Recourse\n",
    "        x_r = lar_recourse.get_recourse(x_0, beta=1.)\n",
    "        weights_r, bias_r = lar_recourse.calc_theta_adv(x_r)\n",
    "        theta_r = np.hstack((weights_r, bias_r))\n",
    "        J_r_opt = J.eval(x_r, weights_r, bias_r)\n",
    "        \n",
    "        # Predictions\n",
    "        predictions = generate_nn_predictions(dataset, theta_0, theta_r, alpha)\n",
    "        \n",
    "        for p, prediction in enumerate(predictions):\n",
    "            weights_p, bias_p = prediction[:-1], prediction[[-1]]\n",
    "            theta_p = (weights_p, bias_p)\n",
    "            \n",
    "            # Consistent Recourse\n",
    "            x_c = lar_recourse.get_recourse(x_0, beta=0., theta_p=theta_p)\n",
    "            J_c_opt = J.eval(x_c, *theta_p)\n",
    "            \n",
    "            # Learning Augmented Recourse\n",
    "            for beta in betas:\n",
    "                # Alg 1\n",
    "                if 'alg1' in params['algs']:\n",
    "                    x = lar_recourse.get_recourse(x_0, beta=beta, theta_p=theta_p)\n",
    "                    weights_r, bias_r = lar_recourse.calc_theta_adv(x)\n",
    "                    theta_r = np.hstack((weights_r, bias_r))\n",
    "                    \n",
    "                    J_r = J.eval(x, weights_r, bias_r)\n",
    "                    J_c = J.eval(x, weights_p, bias_p)\n",
    "                    robustness = J_r - J_r_opt\n",
    "                    consistency = J_c - J_c_opt\n",
    "                    \n",
    "                    append_result(results_opt, 'OPT', seed, alpha, lamb, i, x_0, theta_0, beta, x, theta_r, p, prediction, J_r[0], J_c[0], robustness[0], consistency[0])\n",
    "                \n",
    "                # ROAR\n",
    "                if 'roar' in params['algs']:\n",
    "                    x, _ = roar_recourse.get_recourse(x_0, theta_p, beta)\n",
    "                    weights_r, bias_r = lar_recourse.calc_theta_adv(x)\n",
    "                    theta_r = np.hstack((weights_r, bias_r))\n",
    "                    \n",
    "                    J_r = J.eval(x, weights_r, bias_r)\n",
    "                    J_c = J.eval(x, weights_p, bias_p)\n",
    "                    robustness = J_r - J_r_opt\n",
    "                    consistency = J_c - J_c_opt\n",
    "                    \n",
    "                    append_result(results_roar, 'ROAR', seed, alpha, lamb, i, x_0, theta_0, beta, x, theta_r, p, prediction, J_r[0], J_c[0], robustness[0], consistency[0])\n",
    "                \n",
    "    # Save history\n",
    "    df_results = pd.DataFrame()\n",
    "    if 'alg1' in params['algs']:\n",
    "        df_opt = pd.DataFrame(results_opt)\n",
    "        if params['save_history']:\n",
    "            print(f'[Alg1] Saving history for {dataset.name} run {seed}')\n",
    "            df_opt.to_pickle(f'../results/rob_con_tradeoff/history/nn_{dataset.name}_alg1_{seed}.pkl')\n",
    "        df_opt_agg = df_opt.groupby(['alg', 'p', 'beta'], as_index=False).mean(True)\n",
    "        if params['save_results']:\n",
    "            print(f'[Alg1] Saving results for {dataset.name} run {seed}')\n",
    "            df_opt_agg.to_pickle(f'../results/rob_con_tradeoff/output/nn_{dataset.name}_alg1_{seed}.pkl')\n",
    "        df_results = pd.concat((df_results, df_opt_agg))\n",
    "    \n",
    "    if 'roar' in params['algs']:\n",
    "        df_roar = pd.DataFrame(results_roar)\n",
    "        if params['save_history']:\n",
    "            print(f'[ROAR] Saving history for {dataset.name} run {seed}')\n",
    "            df_roar.to_pickle(f'../results/rob_con_tradeoff/history/nn_{dataset.name}_roar_{seed}.pkl')\n",
    "        df_roar_agg = df_roar.groupby(['alg', 'p', 'beta'], as_index=False).mean(True)\n",
    "        if params['save_results']:\n",
    "            print(f'[ROAR] Saving results for {dataset.name} run {seed}')\n",
    "            df_roar_agg.to_pickle(f'../results/rob_con_tradeoff/output/nn_{dataset.name}_roar_{seed}.pkl')\n",
    "        df_results = pd.concat((df_results, df_roar_agg))\n",
    "    \n",
    "    return df_results\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(dataset: Dataset, params: dict, results: List):\n",
    "    alpha = params['alpha']\n",
    "    \n",
    "    for seed in params['seeds']:\n",
    "        (train_data, test_data) = dataset.get_data(seed)\n",
    "        X_train, y_train = train_data\n",
    "        X_test, y_test = test_data\n",
    "        \n",
    "        base_model = NN(X_train.shape[1])\n",
    "        base_model.train(X_train.values, y_train.values)\n",
    "        \n",
    "        recourse_needed_X_train = recourse_needed(base_model.predict, X_train.values)\n",
    "        recourse_needed_X_test = recourse_needed(base_model.predict, X_test.values)\n",
    "        \n",
    "        weights, bias = None, None\n",
    "        lar_recourse = LARRecourse(weights=weights, bias=bias, alpha=alpha)\n",
    "        roar_recourse = ROAR(weights=weights, bias=bias, alpha=alpha)\n",
    "        \n",
    "        params['lamb'] = lar_recourse.choose_lambda(recourse_needed_X_train, base_model.predict, X_train.values)\n",
    "        lar_recourse.lamb = params['lamb']\n",
    "        roar_recourse.lamb = params['lamb']\n",
    "        \n",
    "        df_results = recourse_runner(seed, X_train.values, recourse_needed_X_test, lar_recourse, roar_recourse, base_model, params, dataset)\n",
    "        results.append(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running synthetic data...\n",
      "Choosing lambda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lambda=0.1: 100%|██████████| 404/404 [00:01<00:00, 206.32it/s]\n",
      "lambda=0.2: 100%|██████████| 404/404 [00:01<00:00, 217.19it/s]\n",
      "lambda=0.3: 100%|██████████| 404/404 [00:01<00:00, 210.31it/s]\n",
      "lambda=0.4: 100%|██████████| 404/404 [00:01<00:00, 237.02it/s]\n",
      "lambda=0.5: 100%|██████████| 404/404 [00:01<00:00, 231.03it/s]\n",
      "lambda=0.6: 100%|██████████| 404/404 [00:01<00:00, 227.97it/s]\n",
      "lambda=0.7: 100%|██████████| 404/404 [00:01<00:00, 224.59it/s]\n",
      "lambda=0.8: 100%|██████████| 404/404 [00:01<00:00, 221.61it/s]\n",
      "lambda=0.9: 100%|██████████| 404/404 [00:01<00:00, 230.53it/s]\n",
      "lambda=1.0: 100%|██████████| 404/404 [00:01<00:00, 213.33it/s]\n",
      "Evaluating recourse | alpha=0.5; lambda=1.0: 100%|\u001b[38;2;0;145;255m██████████\u001b[0m| 96/96 [3:22:57<00:00, 126.85s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ROAR] Saving history for synthetic run 0\n",
      "[ROAR] Saving results for synthetic run 0\n",
      "Choosing lambda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lambda=0.1: 100%|██████████| 405/405 [00:01<00:00, 228.48it/s]\n",
      "lambda=0.2: 100%|██████████| 405/405 [00:01<00:00, 227.39it/s]\n",
      "lambda=0.3: 100%|██████████| 405/405 [00:01<00:00, 234.83it/s]\n",
      "lambda=0.4: 100%|██████████| 405/405 [00:01<00:00, 236.16it/s]\n",
      "lambda=0.5: 100%|██████████| 405/405 [00:01<00:00, 237.18it/s]\n",
      "lambda=0.6: 100%|██████████| 405/405 [00:01<00:00, 235.27it/s]\n",
      "lambda=0.7: 100%|██████████| 405/405 [00:01<00:00, 233.60it/s]\n",
      "lambda=0.8: 100%|██████████| 405/405 [00:01<00:00, 235.83it/s]\n",
      "lambda=0.9: 100%|██████████| 405/405 [00:01<00:00, 236.63it/s]\n",
      "lambda=1.0: 100%|██████████| 405/405 [00:01<00:00, 231.36it/s]\n",
      "Evaluating recourse | alpha=0.5; lambda=1.0: 100%|\u001b[38;2;0;145;255m██████████\u001b[0m| 95/95 [3:05:42<00:00, 117.29s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ROAR] Saving history for synthetic run 1\n",
      "[ROAR] Saving results for synthetic run 1\n",
      "Choosing lambda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lambda=0.1: 100%|██████████| 397/397 [00:01<00:00, 226.85it/s]\n",
      "lambda=0.2: 100%|██████████| 397/397 [00:01<00:00, 234.89it/s]\n",
      "lambda=0.3: 100%|██████████| 397/397 [00:01<00:00, 232.18it/s]\n",
      "lambda=0.4: 100%|██████████| 397/397 [00:01<00:00, 222.80it/s]\n",
      "lambda=0.5: 100%|██████████| 397/397 [00:01<00:00, 233.68it/s]\n",
      "lambda=0.6: 100%|██████████| 397/397 [00:01<00:00, 233.24it/s]\n",
      "lambda=0.7: 100%|██████████| 397/397 [00:01<00:00, 229.57it/s]\n",
      "lambda=0.8: 100%|██████████| 397/397 [00:01<00:00, 236.53it/s]\n",
      "lambda=0.9: 100%|██████████| 397/397 [00:01<00:00, 231.98it/s]\n",
      "lambda=1.0: 100%|██████████| 397/397 [00:01<00:00, 234.80it/s]\n",
      "Evaluating recourse | alpha=0.5; lambda=1.0: 100%|\u001b[38;2;0;145;255m██████████\u001b[0m| 103/103 [3:30:37<00:00, 122.69s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ROAR] Saving history for synthetic run 2\n",
      "[ROAR] Saving results for synthetic run 2\n",
      "Choosing lambda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lambda=0.1: 100%|██████████| 399/399 [00:01<00:00, 217.69it/s]\n",
      "lambda=0.2: 100%|██████████| 399/399 [00:01<00:00, 223.85it/s]\n",
      "lambda=0.3: 100%|██████████| 399/399 [00:01<00:00, 222.30it/s]\n",
      "lambda=0.4: 100%|██████████| 399/399 [00:01<00:00, 219.32it/s]\n",
      "lambda=0.5: 100%|██████████| 399/399 [00:01<00:00, 212.17it/s]\n",
      "lambda=0.6: 100%|██████████| 399/399 [00:01<00:00, 218.09it/s]\n",
      "lambda=0.7: 100%|██████████| 399/399 [00:01<00:00, 218.52it/s]\n",
      "lambda=0.8: 100%|██████████| 399/399 [00:01<00:00, 221.89it/s]\n",
      "lambda=0.9: 100%|██████████| 399/399 [00:01<00:00, 218.37it/s]\n",
      "lambda=1.0: 100%|██████████| 399/399 [00:01<00:00, 211.92it/s]\n",
      "Evaluating recourse | alpha=0.5; lambda=1.0: 100%|\u001b[38;2;0;145;255m██████████\u001b[0m| 101/101 [3:30:31<00:00, 125.06s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ROAR] Saving history for synthetic run 3\n",
      "[ROAR] Saving results for synthetic run 3\n",
      "Choosing lambda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lambda=0.1: 100%|██████████| 395/395 [00:01<00:00, 219.99it/s]\n",
      "lambda=0.2: 100%|██████████| 395/395 [00:01<00:00, 225.31it/s]\n",
      "lambda=0.3: 100%|██████████| 395/395 [00:01<00:00, 217.14it/s]\n",
      "lambda=0.4: 100%|██████████| 395/395 [00:01<00:00, 225.24it/s]\n",
      "lambda=0.5: 100%|██████████| 395/395 [00:01<00:00, 223.30it/s]\n",
      "lambda=0.6: 100%|██████████| 395/395 [00:01<00:00, 222.41it/s]\n",
      "lambda=0.7: 100%|██████████| 395/395 [00:01<00:00, 219.60it/s]\n",
      "lambda=0.8: 100%|██████████| 395/395 [00:01<00:00, 217.66it/s]\n",
      "lambda=0.9: 100%|██████████| 395/395 [00:01<00:00, 216.55it/s]\n",
      "lambda=1.0: 100%|██████████| 395/395 [00:01<00:00, 214.35it/s]\n",
      "Evaluating recourse | alpha=0.5; lambda=1.0: 100%|\u001b[38;2;0;145;255m██████████\u001b[0m| 105/105 [4:23:59<00:00, 150.85s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ROAR] Saving history for synthetic run 4\n",
      "[ROAR] Saving results for synthetic run 4\n",
      "Finished synthetic\n",
      "\n",
      "Running german data...\n",
      "Choosing lambda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lambda=0.1: 100%|██████████| 119/119 [00:00<00:00, 206.45it/s]\n",
      "lambda=0.2: 100%|██████████| 119/119 [00:00<00:00, 211.70it/s]\n",
      "Evaluating recourse | alpha=0.5; lambda=0.1: 100%|\u001b[38;2;0;145;255m██████████\u001b[0m| 37/37 [1:31:44<00:00, 148.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ROAR] Saving history for german run 0\n",
      "[ROAR] Saving results for german run 0\n",
      "Choosing lambda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lambda=0.1: 100%|██████████| 105/105 [00:00<00:00, 208.76it/s]\n",
      "lambda=0.2: 100%|██████████| 105/105 [00:00<00:00, 211.33it/s]\n",
      "lambda=0.3: 100%|██████████| 105/105 [00:00<00:00, 206.42it/s]\n",
      "Evaluating recourse | alpha=0.5; lambda=0.2: 100%|\u001b[38;2;0;145;255m██████████\u001b[0m| 20/20 [52:47<00:00, 158.39s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ROAR] Saving history for german run 1\n",
      "[ROAR] Saving results for german run 1\n",
      "Choosing lambda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lambda=0.1: 100%|██████████| 120/120 [00:00<00:00, 212.12it/s]\n",
      "lambda=0.2: 100%|██████████| 120/120 [00:00<00:00, 210.95it/s]\n",
      "lambda=0.3: 100%|██████████| 120/120 [00:00<00:00, 213.47it/s]\n",
      "lambda=0.4: 100%|██████████| 120/120 [00:00<00:00, 209.64it/s]\n",
      "Evaluating recourse | alpha=0.5; lambda=0.3: 100%|\u001b[38;2;0;145;255m██████████\u001b[0m| 34/34 [56:54<00:00, 100.42s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ROAR] Saving history for german run 2\n",
      "[ROAR] Saving results for german run 2\n",
      "Choosing lambda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lambda=0.1: 100%|██████████| 127/127 [00:00<00:00, 206.33it/s]\n",
      "lambda=0.2: 100%|██████████| 127/127 [00:00<00:00, 207.67it/s]\n",
      "lambda=0.3: 100%|██████████| 127/127 [00:00<00:00, 206.76it/s]\n",
      "Evaluating recourse | alpha=0.5; lambda=0.2: 100%|\u001b[38;2;0;145;255m██████████\u001b[0m| 24/24 [49:40<00:00, 124.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ROAR] Saving history for german run 3\n",
      "[ROAR] Saving results for german run 3\n",
      "Choosing lambda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lambda=0.1: 100%|██████████| 122/122 [00:00<00:00, 214.47it/s]\n",
      "lambda=0.2: 100%|██████████| 122/122 [00:00<00:00, 215.21it/s]\n",
      "lambda=0.3: 100%|██████████| 122/122 [00:00<00:00, 216.65it/s]\n",
      "Evaluating recourse | alpha=0.5; lambda=0.2: 100%|\u001b[38;2;0;145;255m██████████\u001b[0m| 29/29 [1:10:17<00:00, 145.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ROAR] Saving history for german run 4\n",
      "[ROAR] Saving results for german run 4\n",
      "Finished german\n",
      "\n",
      "Running sba data...\n",
      "Choosing lambda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lambda=0.1: 100%|██████████| 150/150 [00:01<00:00, 129.88it/s]\n",
      "lambda=0.2: 100%|██████████| 150/150 [00:01<00:00, 130.39it/s]\n",
      "lambda=0.3: 100%|██████████| 150/150 [00:01<00:00, 129.59it/s]\n",
      "lambda=0.4: 100%|██████████| 150/150 [00:01<00:00, 120.45it/s]\n",
      "lambda=0.5: 100%|██████████| 150/150 [00:01<00:00, 130.18it/s]\n",
      "lambda=0.6: 100%|██████████| 150/150 [00:01<00:00, 130.08it/s]\n",
      "lambda=0.7: 100%|██████████| 150/150 [00:01<00:00, 130.51it/s]\n",
      "lambda=0.8: 100%|██████████| 150/150 [00:01<00:00, 129.25it/s]\n",
      "lambda=0.9: 100%|██████████| 150/150 [00:01<00:00, 128.60it/s]\n",
      "lambda=1.0: 100%|██████████| 150/150 [00:01<00:00, 128.23it/s]\n",
      "Evaluating recourse | alpha=0.5; lambda=1.0: 100%|\u001b[38;2;0;145;255m██████████\u001b[0m| 39/39 [2:55:02<00:00, 269.29s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ROAR] Saving history for sba run 0\n",
      "[ROAR] Saving results for sba run 0\n",
      "Choosing lambda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lambda=0.1: 100%|██████████| 153/153 [00:01<00:00, 123.24it/s]\n",
      "lambda=0.2: 100%|██████████| 153/153 [00:01<00:00, 128.78it/s]\n",
      "lambda=0.3: 100%|██████████| 153/153 [00:01<00:00, 130.16it/s]\n",
      "lambda=0.4: 100%|██████████| 153/153 [00:01<00:00, 127.57it/s]\n",
      "lambda=0.5: 100%|██████████| 153/153 [00:01<00:00, 129.96it/s]\n",
      "lambda=0.6: 100%|██████████| 153/153 [00:01<00:00, 129.50it/s]\n",
      "Evaluating recourse | alpha=0.5; lambda=0.5: 100%|\u001b[38;2;0;145;255m██████████\u001b[0m| 36/36 [4:16:20<00:00, 427.22s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ROAR] Saving history for sba run 1\n",
      "[ROAR] Saving results for sba run 1\n",
      "Choosing lambda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lambda=0.1: 100%|██████████| 149/149 [00:01<00:00, 128.57it/s]\n",
      "lambda=0.2: 100%|██████████| 149/149 [00:01<00:00, 127.86it/s]\n",
      "lambda=0.3: 100%|██████████| 149/149 [00:01<00:00, 129.88it/s]\n",
      "lambda=0.4: 100%|██████████| 149/149 [00:01<00:00, 125.74it/s]\n",
      "lambda=0.5: 100%|██████████| 149/149 [00:01<00:00, 128.57it/s]\n",
      "lambda=0.6: 100%|██████████| 149/149 [00:01<00:00, 128.13it/s]\n",
      "Evaluating recourse | alpha=0.5; lambda=0.5: 100%|\u001b[38;2;0;145;255m██████████\u001b[0m| 39/39 [3:56:36<00:00, 364.01s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ROAR] Saving history for sba run 2\n",
      "[ROAR] Saving results for sba run 2\n",
      "Choosing lambda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lambda=0.1: 100%|██████████| 153/153 [00:01<00:00, 131.46it/s]\n",
      "lambda=0.2: 100%|██████████| 153/153 [00:01<00:00, 135.04it/s]\n",
      "lambda=0.3: 100%|██████████| 153/153 [00:01<00:00, 133.65it/s]\n",
      "lambda=0.4: 100%|██████████| 153/153 [00:01<00:00, 134.61it/s]\n",
      "lambda=0.5: 100%|██████████| 153/153 [00:01<00:00, 132.53it/s]\n",
      "lambda=0.6: 100%|██████████| 153/153 [00:01<00:00, 134.26it/s]\n",
      "Evaluating recourse | alpha=0.5; lambda=0.5: 100%|\u001b[38;2;0;145;255m██████████\u001b[0m| 36/36 [6:01:09<00:00, 601.93s/it]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ROAR] Saving history for sba run 3\n",
      "[ROAR] Saving results for sba run 3\n",
      "Choosing lambda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lambda=0.1: 100%|██████████| 151/151 [00:01<00:00, 129.13it/s]\n",
      "lambda=0.2: 100%|██████████| 151/151 [00:01<00:00, 134.15it/s]\n",
      "lambda=0.3: 100%|██████████| 151/151 [00:01<00:00, 132.91it/s]\n",
      "lambda=0.4: 100%|██████████| 151/151 [00:01<00:00, 133.38it/s]\n",
      "lambda=0.5: 100%|██████████| 151/151 [00:01<00:00, 128.11it/s]\n",
      "lambda=0.6: 100%|██████████| 151/151 [00:01<00:00, 132.72it/s]\n",
      "Evaluating recourse | alpha=0.5; lambda=0.5: 100%|\u001b[38;2;0;145;255m██████████\u001b[0m| 38/38 [8:51:15<00:00, 838.83s/it]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ROAR] Saving history for sba run 4\n",
      "[ROAR] Saving results for sba run 4\n",
      "Finished sba\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "d_results = {}\n",
    "params = {}\n",
    "params['alpha'] = 0.5\n",
    "params['lamb'] = None\n",
    "params['seeds'] = range(5)\n",
    "params['algs'] = ['roar'] # 'alg1', 'roar\n",
    "params['save_results'] = True\n",
    "params['save_history'] = True\n",
    "params['save_final_results'] = False\n",
    "\n",
    "\n",
    "datasets = [SyntheticDataset(), GermanDataset(), SBADataset()]\n",
    "for dataset in datasets:\n",
    "    results = []\n",
    "    \n",
    "    print(f'Running {dataset.name} data...')\n",
    "    run_experiment(dataset, params, results)\n",
    "    \n",
    "    d_results[dataset.name] = pd.concat(results)\n",
    "    if params['save_final_results']:\n",
    "        d_results[dataset.name].to_pickle(f'../results/rob_con_tradeoff/output/nn_{dataset.name}')\n",
    "    \n",
    "    \n",
    "    print(f'Finished {dataset.name}\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
