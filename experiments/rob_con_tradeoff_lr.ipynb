{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from copy import deepcopy\n",
    "\n",
    "from src.data import *\n",
    "from src.model import *\n",
    "from src.recourse import *\n",
    "from src.utils import *\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_result(d, alg_name, seed, alpha, lamb, i, x_0, theta_0, beta, x_r, theta_r, p, theta_p, J_r, J_c, robustness, consistency):\n",
    "    d['alg'].append(alg_name)\n",
    "    d['seed'].append(seed)\n",
    "    d['alpha'].append(alpha)\n",
    "    d['lambda'].append(lamb)\n",
    "    d['i'].append(i)\n",
    "    d['x_0'].append(x_0.round(4))\n",
    "    d['theta_0'].append(theta_0.round(4))\n",
    "    d['beta'].append(beta)\n",
    "    d['x_r'].append(x_r.round(4))\n",
    "    d['theta_r'].append(theta_r.round(4))\n",
    "    d['p'].append(p)\n",
    "    d['theta_p'].append(theta_p.round(4))\n",
    "    d['J_r'].append(J_r)\n",
    "    d['J_c'].append(J_c)\n",
    "    d['robustness'].append(robustness)\n",
    "    d['consistency'].append(consistency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recourse_runner(seed: int, X: np.ndarray, lar_recourse: LARRecourse, roar_recourse: ROAR, params: dict, dataset: Dataset, predictions: List):\n",
    "    alpha = params['alpha']\n",
    "    lamb = params['lamb']\n",
    "    params['algs'] = [alg.lower() for alg in params['algs']]\n",
    "    betas = np.arange(0., 1.01, 0.01).round(2)\n",
    "    \n",
    "    results_opt = {'alg': [], 'seed': [], 'alpha': [], 'lambda': [], 'i': [], 'x_0': [], 'theta_0': [], 'beta': [], 'x_r': [], 'theta_r': [], 'p': [], 'theta_p': [], 'J_r': [], 'J_c': [], 'robustness': [], 'consistency': []}\n",
    "    results_roar = deepcopy(results_opt)\n",
    "    weights_0, bias_0 = lar_recourse.weights, lar_recourse.bias\n",
    "    theta_0 = np.hstack((weights_0, bias_0))\n",
    "    \n",
    "    n = len(X)\n",
    "    for i in tqdm.trange(n, desc=f'Evaluating recourse | alpha={alpha}; lambda={lamb}', colour='#0091ff'):\n",
    "        x_0 = X[i]\n",
    "        J = RecourseCost(x_0, lamb)\n",
    "        \n",
    "        # Robust Recourse\n",
    "        x_r = lar_recourse.get_recourse(x_0, beta=1.)\n",
    "        weights_r, bias_r = lar_recourse.calc_theta_adv(x_r)\n",
    "        theta_r = np.hstack((weights_r, bias_r))\n",
    "        J_r_opt = J.eval(x_r, weights_r, bias_r)\n",
    "        \n",
    "        for p, prediction in enumerate(predictions):\n",
    "            weights_p, bias_p = prediction[:-1], prediction[[-1]]\n",
    "            theta_p = (weights_p, bias_p)\n",
    "            \n",
    "            # Consistent Recourse\n",
    "            x_c = lar_recourse.get_recourse(x_0, beta=0., theta_p=theta_p)\n",
    "            J_c_opt = J.eval(x_c, *theta_p)\n",
    "            \n",
    "            # Learning Augmented Recourse\n",
    "            for beta in betas:\n",
    "                # Alg 1\n",
    "                if 'alg1' in params['algs']:\n",
    "                    x = lar_recourse.get_recourse(x_0, beta=beta, theta_p=theta_p)\n",
    "                    weights_r, bias_r = lar_recourse.calc_theta_adv(x)\n",
    "                    theta_r = np.hstack((weights_r, bias_r))\n",
    "                    \n",
    "                    J_r = J.eval(x, weights_r, bias_r)\n",
    "                    J_c = J.eval(x, weights_p, bias_p)\n",
    "                    robustness = J_r - J_r_opt\n",
    "                    consistency = J_c - J_c_opt\n",
    "                    \n",
    "                    append_result(results_opt, 'OPT', seed, alpha, lamb, i, x_0, theta_0, beta, x, theta_r, p, prediction, J_r[0], J_c[0], robustness[0], consistency[0])\n",
    "                \n",
    "                # ROAR\n",
    "                if 'roar' in params['algs']:\n",
    "                    x, _ = roar_recourse.get_recourse(x_0, theta_p, beta)\n",
    "                    weights_r, bias_r = lar_recourse.calc_theta_adv(x)\n",
    "                    theta_r = np.hstack((weights_r, bias_r))\n",
    "                    \n",
    "                    J_r = J.eval(x, weights_r, bias_r)\n",
    "                    J_c = J.eval(x, weights_p, bias_p)\n",
    "                    robustness = J_r - J_r_opt\n",
    "                    consistency = J_c - J_c_opt\n",
    "                    \n",
    "                    append_result(results_roar, 'ROAR', seed, alpha, lamb, i, x_0, theta_0, beta, x, theta_r, p, prediction, J_r[0], J_c[0], robustness[0], consistency[0])\n",
    "                \n",
    "    # Save results\n",
    "    df_results = pd.DataFrame()\n",
    "    if 'alg1' in params['algs']:\n",
    "        df_opt = pd.DataFrame(results_opt)\n",
    "        if params['save_history']:\n",
    "            print(f'[Alg1] Saving history for {dataset.name} run {seed}')\n",
    "            df_opt.to_pickle(f'../results/rob_con_tradeoff/history/lr_{dataset.name}_alg1_{seed}.pkl')\n",
    "        df_opt_agg = df_opt.groupby(['alg', 'p', 'beta'], as_index=False).mean(True)\n",
    "        if params['save_results']:\n",
    "            print(f'[Alg1] Saving results for {dataset.name} run {seed}')\n",
    "            df_opt_agg.to_pickle(f'../results/rob_con_tradeoff/output/lr_{dataset.name}_alg1_{seed}.pkl')\n",
    "        df_results = pd.concat((df_results, df_opt_agg))\n",
    "    \n",
    "    if 'roar' in params['algs']:\n",
    "        df_roar = pd.DataFrame(results_roar)\n",
    "        if params['save_history']:\n",
    "            print(f'[ROAR] Saving history for {dataset.name} run {seed}')\n",
    "            df_roar.to_pickle(f'../results/rob_con_tradeoff/history/lr_{dataset.name}_roar_{seed}.pkl')\n",
    "        df_roar_agg = df_roar.groupby(['alg', 'p', 'beta'], as_index=False).mean(True)\n",
    "        if params['save_results']:\n",
    "            print(f'[ROAR] Saving results for {dataset.name} run {seed}')\n",
    "            df_roar_agg.to_pickle(f'../results/rob_con_tradeoff/output/lr_{dataset.name}_roar_{seed}.pkl')\n",
    "        df_results = pd.concat((df_results, df_roar_agg))\n",
    "    \n",
    "    return df_results\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(dataset: Dataset, params: dict, results: List):\n",
    "    alpha = params['alpha']\n",
    "    predictions = []\n",
    "    \n",
    "    for seed in params['seeds']:\n",
    "        (train_data, test_data) = dataset.get_data(seed)\n",
    "        X_train, y_train = train_data\n",
    "        X_test, y_test = test_data\n",
    "        \n",
    "        base_model = LR()\n",
    "        base_model.train(X_train.values, y_train.values)\n",
    "        \n",
    "        weights_0 = base_model.model.coef_[0]\n",
    "        bias_0 = base_model.model.intercept_\n",
    "        theta_0 = np.hstack((weights_0, bias_0))\n",
    "        \n",
    "        if not predictions:\n",
    "            predictions = generate_lr_predictions(dataset, theta_0, alpha)\n",
    "        \n",
    "        recourse_needed_X_train = recourse_needed(base_model.predict, X_train.values)\n",
    "        recourse_needed_X_test = recourse_needed(base_model.predict, X_test.values)\n",
    "        \n",
    "        lar_recourse = LARRecourse(weights=weights_0, bias=bias_0, alpha=alpha)\n",
    "        roar_recourse = ROAR(weights=weights_0, bias=bias_0, alpha=alpha)\n",
    "        \n",
    "        params['lamb'] = lar_recourse.choose_lambda(recourse_needed_X_train, base_model.predict, X_train.values)\n",
    "        lar_recourse.lamb = params['lamb']\n",
    "        roar_recourse.lamb = params['lamb']\n",
    "        \n",
    "        df_results = recourse_runner(seed, recourse_needed_X_test, lar_recourse, roar_recourse, params, dataset, predictions)\n",
    "        results.append(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running synthetic data...\n",
      "Choosing lambda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lambda=0.1: 100%|██████████| 404/404 [00:00<00:00, 31172.94it/s]\n",
      "lambda=0.2: 100%|██████████| 404/404 [00:00<00:00, 28416.88it/s]\n",
      "lambda=0.3: 100%|██████████| 404/404 [00:00<00:00, 30818.60it/s]\n",
      "lambda=0.4: 100%|██████████| 404/404 [00:00<00:00, 32012.14it/s]\n",
      "lambda=0.5: 100%|██████████| 404/404 [00:00<00:00, 31666.36it/s]\n",
      "lambda=0.6: 100%|██████████| 404/404 [00:00<00:00, 33629.68it/s]\n",
      "lambda=0.7: 100%|██████████| 404/404 [00:00<00:00, 31639.17it/s]\n",
      "lambda=0.8: 100%|██████████| 404/404 [00:00<00:00, 32646.16it/s]\n",
      "lambda=0.9: 100%|██████████| 404/404 [00:00<00:00, 32483.44it/s]\n",
      "lambda=1.0: 100%|██████████| 404/404 [00:00<00:00, 31252.86it/s]\n",
      "Evaluating recourse | alpha=0.5; lambda=1.0: 100%|\u001b[38;2;0;145;255m██████████\u001b[0m| 96/96 [7:29:43<00:00, 281.08s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ROAR] Saving history for synthetic run 0\n",
      "[ROAR] Saving results for synthetic run 0\n",
      "Choosing lambda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lambda=0.1: 100%|██████████| 405/405 [00:00<00:00, 31404.94it/s]\n",
      "lambda=0.2: 100%|██████████| 405/405 [00:00<00:00, 33077.46it/s]\n",
      "lambda=0.3: 100%|██████████| 405/405 [00:00<00:00, 32203.93it/s]\n",
      "lambda=0.4: 100%|██████████| 405/405 [00:00<00:00, 33202.24it/s]\n",
      "lambda=0.5: 100%|██████████| 405/405 [00:00<00:00, 33015.75it/s]\n",
      "lambda=0.6: 100%|██████████| 405/405 [00:00<00:00, 32708.69it/s]\n",
      "lambda=0.7: 100%|██████████| 405/405 [00:00<00:00, 31790.49it/s]\n",
      "lambda=0.8: 100%|██████████| 405/405 [00:00<00:00, 33147.17it/s]\n",
      "lambda=0.9: 100%|██████████| 405/405 [00:00<00:00, 31822.06it/s]\n",
      "lambda=1.0: 100%|██████████| 405/405 [00:00<00:00, 32949.14it/s]\n",
      "Evaluating recourse | alpha=0.5; lambda=1.0: 100%|\u001b[38;2;0;145;255m██████████\u001b[0m| 95/95 [8:02:45<00:00, 304.90s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ROAR] Saving history for synthetic run 1\n",
      "[ROAR] Saving results for synthetic run 1\n",
      "Choosing lambda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lambda=0.1: 100%|██████████| 397/397 [00:00<00:00, 37030.24it/s]\n",
      "lambda=0.2: 100%|██████████| 397/397 [00:00<00:00, 33075.22it/s]\n",
      "lambda=0.3: 100%|██████████| 397/397 [00:00<00:00, 33578.11it/s]\n",
      "lambda=0.4: 100%|██████████| 397/397 [00:00<00:00, 34754.11it/s]\n",
      "lambda=0.5: 100%|██████████| 397/397 [00:00<00:00, 33752.36it/s]\n",
      "lambda=0.6: 100%|██████████| 397/397 [00:00<00:00, 34053.31it/s]\n",
      "lambda=0.7: 100%|██████████| 397/397 [00:00<00:00, 32242.01it/s]\n",
      "lambda=0.8: 100%|██████████| 397/397 [00:00<00:00, 32905.28it/s]\n",
      "lambda=0.9: 100%|██████████| 397/397 [00:00<00:00, 32245.13it/s]\n",
      "lambda=1.0: 100%|██████████| 397/397 [00:00<00:00, 33700.44it/s]\n",
      "Evaluating recourse | alpha=0.5; lambda=1.0: 100%|\u001b[38;2;0;145;255m██████████\u001b[0m| 103/103 [8:18:53<00:00, 290.62s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ROAR] Saving history for synthetic run 2\n",
      "[ROAR] Saving results for synthetic run 2\n",
      "Choosing lambda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lambda=0.1: 100%|██████████| 399/399 [00:00<00:00, 36930.98it/s]\n",
      "lambda=0.2: 100%|██████████| 399/399 [00:00<00:00, 31584.33it/s]\n",
      "lambda=0.3: 100%|██████████| 399/399 [00:00<00:00, 36431.72it/s]\n",
      "lambda=0.4: 100%|██████████| 399/399 [00:00<00:00, 31920.49it/s]\n",
      "lambda=0.5: 100%|██████████| 399/399 [00:00<00:00, 32646.55it/s]\n",
      "lambda=0.6: 100%|██████████| 399/399 [00:00<00:00, 33733.67it/s]\n",
      "lambda=0.7: 100%|██████████| 399/399 [00:00<00:00, 33498.68it/s]\n",
      "lambda=0.8: 100%|██████████| 399/399 [00:00<00:00, 32070.97it/s]\n",
      "lambda=0.9: 100%|██████████| 399/399 [00:00<00:00, 37709.04it/s]\n",
      "lambda=1.0: 100%|██████████| 399/399 [00:00<00:00, 32791.11it/s]\n",
      "Evaluating recourse | alpha=0.5; lambda=1.0: 100%|\u001b[38;2;0;145;255m██████████\u001b[0m| 101/101 [8:12:59<00:00, 292.86s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ROAR] Saving history for synthetic run 3\n",
      "[ROAR] Saving results for synthetic run 3\n",
      "Choosing lambda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lambda=0.1: 100%|██████████| 395/395 [00:00<00:00, 32124.37it/s]\n",
      "lambda=0.2: 100%|██████████| 395/395 [00:00<00:00, 32174.28it/s]\n",
      "lambda=0.3: 100%|██████████| 395/395 [00:00<00:00, 32226.22it/s]\n",
      "lambda=0.4: 100%|██████████| 395/395 [00:00<00:00, 32510.79it/s]\n",
      "lambda=0.5: 100%|██████████| 395/395 [00:00<00:00, 33551.03it/s]\n",
      "lambda=0.6: 100%|██████████| 395/395 [00:00<00:00, 32635.68it/s]\n",
      "lambda=0.7: 100%|██████████| 395/395 [00:00<00:00, 32134.34it/s]\n",
      "lambda=0.8: 100%|██████████| 395/395 [00:00<00:00, 32319.26it/s]\n",
      "lambda=0.9: 100%|██████████| 395/395 [00:00<00:00, 33068.20it/s]\n",
      "lambda=1.0: 100%|██████████| 395/395 [00:00<00:00, 33129.04it/s]\n",
      "Evaluating recourse | alpha=0.5; lambda=1.0: 100%|\u001b[38;2;0;145;255m██████████\u001b[0m| 105/105 [11:44:12<00:00, 402.41s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ROAR] Saving history for synthetic run 4\n",
      "[ROAR] Saving results for synthetic run 4\n",
      "Finished synthetic\n",
      "\n",
      "Running german data...\n",
      "Choosing lambda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lambda=0.1: 100%|██████████| 63/63 [00:00<00:00, 17842.08it/s]\n",
      "lambda=0.2: 100%|██████████| 63/63 [00:00<00:00, 20690.72it/s]\n",
      "lambda=0.3: 100%|██████████| 63/63 [00:00<00:00, 24762.55it/s]\n",
      "lambda=0.4: 100%|██████████| 63/63 [00:00<00:00, 24129.41it/s]\n",
      "lambda=0.5: 100%|██████████| 63/63 [00:00<00:00, 38962.13it/s]\n",
      "lambda=0.6: 100%|██████████| 63/63 [00:00<00:00, 44143.19it/s]\n",
      "lambda=0.7: 100%|██████████| 63/63 [00:00<00:00, 53479.29it/s]\n",
      "lambda=0.8: 100%|██████████| 63/63 [00:00<00:00, 49604.12it/s]\n",
      "Evaluating recourse | alpha=0.5; lambda=0.7: 100%|\u001b[38;2;0;145;255m██████████\u001b[0m| 16/16 [01:02<00:00,  3.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ROAR] Saving history for german run 0\n",
      "[ROAR] Saving results for german run 0\n",
      "Choosing lambda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lambda=0.1: 100%|██████████| 33/33 [00:00<00:00, 14158.35it/s]\n",
      "lambda=0.2: 100%|██████████| 33/33 [00:00<00:00, 16846.64it/s]\n",
      "lambda=0.3: 100%|██████████| 33/33 [00:00<00:00, 22634.84it/s]\n",
      "lambda=0.4: 100%|██████████| 33/33 [00:00<00:00, 23337.05it/s]\n",
      "lambda=0.5: 100%|██████████| 33/33 [00:00<00:00, 28305.12it/s]\n",
      "lambda=0.6: 100%|██████████| 33/33 [00:00<00:00, 27451.81it/s]\n",
      "lambda=0.7: 100%|██████████| 33/33 [00:00<00:00, 46045.25it/s]\n",
      "lambda=0.8: 100%|██████████| 33/33 [00:00<00:00, 64168.77it/s]\n",
      "Evaluating recourse | alpha=0.5; lambda=0.7: 100%|\u001b[38;2;0;145;255m██████████\u001b[0m| 12/12 [00:15<00:00,  1.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ROAR] Saving history for german run 1\n",
      "[ROAR] Saving results for german run 1\n",
      "Choosing lambda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lambda=0.1: 100%|██████████| 70/70 [00:00<00:00, 18995.94it/s]\n",
      "lambda=0.2: 100%|██████████| 70/70 [00:00<00:00, 17799.41it/s]\n",
      "lambda=0.3: 100%|██████████| 70/70 [00:00<00:00, 22299.96it/s]\n",
      "lambda=0.4: 100%|██████████| 70/70 [00:00<00:00, 26995.34it/s]\n",
      "lambda=0.5: 100%|██████████| 70/70 [00:00<00:00, 34115.88it/s]\n",
      "lambda=0.6: 100%|██████████| 70/70 [00:00<00:00, 37962.41it/s]\n",
      "Evaluating recourse | alpha=0.5; lambda=0.5: 100%|\u001b[38;2;0;145;255m██████████\u001b[0m| 11/11 [00:20<00:00,  1.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ROAR] Saving history for german run 2\n",
      "[ROAR] Saving results for german run 2\n",
      "Choosing lambda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lambda=0.1: 100%|██████████| 61/61 [00:00<00:00, 16038.90it/s]\n",
      "lambda=0.2: 100%|██████████| 61/61 [00:00<00:00, 17936.94it/s]\n",
      "lambda=0.3: 100%|██████████| 61/61 [00:00<00:00, 22236.45it/s]\n",
      "lambda=0.4: 100%|██████████| 61/61 [00:00<00:00, 25966.97it/s]\n",
      "lambda=0.5: 100%|██████████| 61/61 [00:00<00:00, 36420.29it/s]\n",
      "lambda=0.6: 100%|██████████| 61/61 [00:00<00:00, 35584.50it/s]\n",
      "lambda=0.7: 100%|██████████| 61/61 [00:00<00:00, 43728.00it/s]\n",
      "lambda=0.8: 100%|██████████| 61/61 [00:00<00:00, 50167.17it/s]\n",
      "Evaluating recourse | alpha=0.5; lambda=0.7: 100%|\u001b[38;2;0;145;255m██████████\u001b[0m| 15/15 [04:31<00:00, 18.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ROAR] Saving history for german run 3\n",
      "[ROAR] Saving results for german run 3\n",
      "Choosing lambda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lambda=0.1: 100%|██████████| 57/57 [00:00<00:00, 18434.37it/s]\n",
      "lambda=0.2: 100%|██████████| 57/57 [00:00<00:00, 17772.47it/s]\n",
      "lambda=0.3: 100%|██████████| 57/57 [00:00<00:00, 22637.57it/s]\n",
      "lambda=0.4: 100%|██████████| 57/57 [00:00<00:00, 8314.80it/s]\n",
      "lambda=0.5: 100%|██████████| 57/57 [00:00<00:00, 22968.14it/s]\n",
      "lambda=0.6: 100%|██████████| 57/57 [00:00<00:00, 23838.40it/s]\n",
      "lambda=0.7: 100%|██████████| 57/57 [00:00<00:00, 30174.85it/s]\n",
      "lambda=0.8: 100%|██████████| 57/57 [00:00<00:00, 41578.32it/s]\n",
      "Evaluating recourse | alpha=0.5; lambda=0.7: 100%|\u001b[38;2;0;145;255m██████████\u001b[0m| 14/14 [00:17<00:00,  1.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ROAR] Saving history for german run 4\n",
      "[ROAR] Saving results for german run 4\n",
      "Finished german\n",
      "\n",
      "Running sba data...\n",
      "Choosing lambda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lambda=0.1: 100%|██████████| 150/150 [00:00<00:00, 32730.50it/s]\n",
      "lambda=0.2: 100%|██████████| 150/150 [00:00<00:00, 27546.99it/s]\n",
      "lambda=0.3: 100%|██████████| 150/150 [00:00<00:00, 27854.32it/s]\n",
      "lambda=0.4: 100%|██████████| 150/150 [00:00<00:00, 29255.78it/s]\n",
      "lambda=0.5: 100%|██████████| 150/150 [00:00<00:00, 27376.77it/s]\n",
      "lambda=0.6: 100%|██████████| 150/150 [00:00<00:00, 27331.58it/s]\n",
      "lambda=0.7: 100%|██████████| 150/150 [00:00<00:00, 27252.26it/s]\n",
      "lambda=0.8: 100%|██████████| 150/150 [00:00<00:00, 27351.78it/s]\n",
      "lambda=0.9: 100%|██████████| 150/150 [00:00<00:00, 27406.59it/s]\n",
      "lambda=1.0: 100%|██████████| 150/150 [00:00<00:00, 26989.22it/s]\n",
      "Evaluating recourse | alpha=0.5; lambda=1.0: 100%|\u001b[38;2;0;145;255m██████████\u001b[0m| 39/39 [6:00:14<00:00, 554.23s/it]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ROAR] Saving history for sba run 0\n",
      "[ROAR] Saving results for sba run 0\n",
      "Choosing lambda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lambda=0.1: 100%|██████████| 153/153 [00:00<00:00, 27909.73it/s]\n",
      "lambda=0.2: 100%|██████████| 153/153 [00:00<00:00, 26001.97it/s]\n",
      "lambda=0.3: 100%|██████████| 153/153 [00:00<00:00, 30254.51it/s]\n",
      "lambda=0.4: 100%|██████████| 153/153 [00:00<00:00, 27321.55it/s]\n",
      "lambda=0.5: 100%|██████████| 153/153 [00:00<00:00, 26257.30it/s]\n",
      "lambda=0.6: 100%|██████████| 153/153 [00:00<00:00, 27065.73it/s]\n",
      "lambda=0.7: 100%|██████████| 153/153 [00:00<00:00, 27667.87it/s]\n",
      "lambda=0.8: 100%|██████████| 153/153 [00:00<00:00, 26118.38it/s]\n",
      "lambda=0.9: 100%|██████████| 153/153 [00:00<00:00, 26832.60it/s]\n",
      "lambda=1.0: 100%|██████████| 153/153 [00:00<00:00, 26688.65it/s]\n",
      "Evaluating recourse | alpha=0.5; lambda=1.0: 100%|\u001b[38;2;0;145;255m██████████\u001b[0m| 36/36 [2:52:08<00:00, 286.90s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ROAR] Saving history for sba run 1\n",
      "[ROAR] Saving results for sba run 1\n",
      "Choosing lambda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lambda=0.1: 100%|██████████| 149/149 [00:00<00:00, 28687.23it/s]\n",
      "lambda=0.2: 100%|██████████| 149/149 [00:00<00:00, 28435.31it/s]\n",
      "lambda=0.3: 100%|██████████| 149/149 [00:00<00:00, 27076.44it/s]\n",
      "lambda=0.4: 100%|██████████| 149/149 [00:00<00:00, 26967.78it/s]\n",
      "lambda=0.5: 100%|██████████| 149/149 [00:00<00:00, 27918.31it/s]\n",
      "lambda=0.6: 100%|██████████| 149/149 [00:00<00:00, 29979.43it/s]\n",
      "lambda=0.7: 100%|██████████| 149/149 [00:00<00:00, 26446.25it/s]\n",
      "lambda=0.8: 100%|██████████| 149/149 [00:00<00:00, 26348.13it/s]\n",
      "lambda=0.9: 100%|██████████| 149/149 [00:00<00:00, 28375.92it/s]\n",
      "lambda=1.0: 100%|██████████| 149/149 [00:00<00:00, 26640.15it/s]\n",
      "Evaluating recourse | alpha=0.5; lambda=1.0: 100%|\u001b[38;2;0;145;255m██████████\u001b[0m| 40/40 [3:10:02<00:00, 285.07s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ROAR] Saving history for sba run 2\n",
      "[ROAR] Saving results for sba run 2\n",
      "Choosing lambda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lambda=0.1: 100%|██████████| 153/153 [00:00<00:00, 27478.31it/s]\n",
      "lambda=0.2: 100%|██████████| 153/153 [00:00<00:00, 26526.48it/s]\n",
      "lambda=0.3: 100%|██████████| 153/153 [00:00<00:00, 27064.59it/s]\n",
      "lambda=0.4: 100%|██████████| 153/153 [00:00<00:00, 26171.64it/s]\n",
      "lambda=0.5: 100%|██████████| 153/153 [00:00<00:00, 25810.58it/s]\n",
      "lambda=0.6: 100%|██████████| 153/153 [00:00<00:00, 26955.45it/s]\n",
      "lambda=0.7: 100%|██████████| 153/153 [00:00<00:00, 26020.94it/s]\n",
      "lambda=0.8: 100%|██████████| 153/153 [00:00<00:00, 27488.91it/s]\n",
      "lambda=0.9: 100%|██████████| 153/153 [00:00<00:00, 27849.17it/s]\n",
      "lambda=1.0: 100%|██████████| 153/153 [00:00<00:00, 27326.20it/s]\n",
      "Evaluating recourse | alpha=0.5; lambda=1.0: 100%|\u001b[38;2;0;145;255m██████████\u001b[0m| 36/36 [3:05:09<00:00, 308.59s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ROAR] Saving history for sba run 3\n",
      "[ROAR] Saving results for sba run 3\n",
      "Choosing lambda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lambda=0.1: 100%|██████████| 151/151 [00:00<00:00, 27746.43it/s]\n",
      "lambda=0.2: 100%|██████████| 151/151 [00:00<00:00, 28734.63it/s]\n",
      "lambda=0.3: 100%|██████████| 151/151 [00:00<00:00, 25515.26it/s]\n",
      "lambda=0.4: 100%|██████████| 151/151 [00:00<00:00, 28527.54it/s]\n",
      "lambda=0.5: 100%|██████████| 151/151 [00:00<00:00, 27768.32it/s]\n",
      "lambda=0.6: 100%|██████████| 151/151 [00:00<00:00, 26463.04it/s]\n",
      "lambda=0.7: 100%|██████████| 151/151 [00:00<00:00, 30358.54it/s]\n",
      "lambda=0.8: 100%|██████████| 151/151 [00:00<00:00, 27202.99it/s]\n",
      "lambda=0.9: 100%|██████████| 151/151 [00:00<00:00, 28251.40it/s]\n",
      "lambda=1.0: 100%|██████████| 151/151 [00:00<00:00, 27736.70it/s]\n",
      "Evaluating recourse | alpha=0.5; lambda=1.0: 100%|\u001b[38;2;0;145;255m██████████\u001b[0m| 38/38 [20:58:24<00:00, 1986.95s/it]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ROAR] Saving history for sba run 4\n",
      "[ROAR] Saving results for sba run 4\n",
      "Finished sba\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "d_results = {}\n",
    "params = {}\n",
    "params['alpha'] = 0.5\n",
    "params['lamb'] = None\n",
    "params['seeds'] = range(5)\n",
    "params['algs'] = ['roar'] # 'alg1', 'roar\n",
    "params['save_results'] = True\n",
    "params['save_history'] = True\n",
    "params['save_final_results'] = False\n",
    "\n",
    "\n",
    "datasets = [SyntheticDataset(), GermanDataset(), SBADataset()]\n",
    "for dataset in datasets:\n",
    "    results = []\n",
    "    \n",
    "    print(f'Running {dataset.name} data...')\n",
    "    run_experiment(dataset, params, results)\n",
    "    \n",
    "    d_results[dataset.name] = pd.concat(results)\n",
    "    if params['save_final_results']:\n",
    "        d_results[dataset.name].to_pickle(f'../results/rob_con_tradeoff/output/lr_{dataset.name}')\n",
    "    \n",
    "    \n",
    "    print(f'Finished {dataset.name}\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
